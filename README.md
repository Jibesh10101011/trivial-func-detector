## Description
This project develops a system that automatically detects and filters **trivial utility functions** (like formatters, helpers, loggers, and simple wrappers) from large Python codebases â€” focusing the analysis on meaningful, business-critical logic.  

The solution uses a hybrid approach combining **static code analysis** and **machine learning** to improve classification accuracy and reduce false positives.

---

## Setup Instructions

1. **Install required libraries**
    
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

2. **Navigate to the main working directory**
    ```bash
    cd utility-filter-pipeline
    ```

---

## Model Development Workflow

### 1ï¸âƒ£ Extract Features

Run static feature extraction from the input dataset:

```bash
python3 feature_extraction.py analysis-with-code.json output/features.csv
```

This step computes various static metrics like:  
`loc`, `cyclomatic_complexity`, `num_statements`, `num_returns`, `num_calls`, `fan_in`, `fan_out`, `pagerank`, `betweenness`, `constant_ratio`, `comment_ratio`, etc.

âœ… **Output:** `output/features.csv`

---

### 2ï¸âƒ£ Generate Labels

Label functions as `core` or `utility` manually/semi-automatically for training:

```bash
python3 generate_labels.py output/features.csv output/labeling.csv
```

âœ… **Output:** `output/labeling.csv`

---

### 3ï¸âƒ£ Train the ML Model

Train a **RandomForestClassifier** model using the generated labels:

```bash
python3 train_model.py output/features.csv output/labeling.csv model/model.joblib
```

The model automatically learns feature weights instead of relying on manual weight tuning.  
Achieved **~98% accuracy (ROC-AUC: 0.995)**.

<img width="662" height="264" alt="image" src="https://github.com/user-attachments/assets/bed5042c-fbd1-48a1-bfc1-33baaf5765ac" />


âœ… **Output:** `model/model.joblib`

---

### 4ï¸âƒ£ Analyze Dataset

Run analysis on the provided dataset and classify each function as *core* or *utility*:

```bash
python3 analyze.py analysis-with-code.json output/results.json
```

âœ… **Output:** `output/results.json`  
Contains predicted labels, confidence scores, and importance metrics.

---

### 5ï¸âƒ£ Rank Nodes by Importance

Rank all nodes by their business logic importance:

```bash
python3 score_all.py output/features.csv model/model.joblib output/ranked_nodes.json
```

âœ… **Output:** `output/ranked_nodes.json`  
Ranks nodes by their **core relevance** while filtering trivial ones.

---

### 6ï¸âƒ£ Test Model on New Dataset

Test the trained model with unseen data to evaluate generalization:

```bash
python3 predict.py model/model.joblib testing/new_analysis.json testing/output/predictions.csv
```

âœ… **Output:** `testing/output/predictions.csv`

---

### ğŸ§­ End-to-End Workflow Diagram

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ analysis-with-code.jsonâ”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ feature_extraction.py     â”‚
     â”‚ â†’ Extract static features â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ generate_labels.py        â”‚
     â”‚ â†’ Create labeled dataset  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ train_model.py            â”‚
     â”‚ â†’ Train Random Forest     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ analyze.py                â”‚
     â”‚ â†’ Predict core/utility    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ score_all.py              â”‚
     â”‚ â†’ Rank function importanceâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ predict.py                â”‚
     â”‚ â†’ Test on new dataset     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Novelty of this Approach

Unlike purely heuristic or rule-based detection (which depends on fixed weights and thresholds), this approach:
- **Learns from data**: ML model infers which features indicate utility behavior.  
- **Reduces false positives**: Uses contextual graph and code structure signals.  
- **Combines static + semantic analysis**: Extracts both structural and linguistic cues from code.  
- **Scalable for new repositories**: Can easily be retrained with new labeled data.  

---

## ğŸ Summary

| Step | Script | Purpose | Output |
|------|---------|----------|---------|
| 1 | `feature_extraction.py` | Extracts static features | `features.csv` |
| 2 | `generate_labels.py` | Creates labeled dataset | `labeling.csv` |
| 3 | `train_model.py` | Trains RandomForest model | `model.joblib` |
| 4 | `analyze.py` | Predicts and classifies nodes | `results.json` |
| 5 | `score_all.py` | Ranks node importance | `ranked_nodes.json` |
| 6 | `predict.py` | Tests on new data | `predictions.csv` |

---

**Final Deliverable:**  
A fully functional service (via FastAPI) that accepts a JSON input of code nodes and outputs their classification (`core` vs `utility`) along with a confidence score and ranking.

